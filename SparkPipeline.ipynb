{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create spark session on local machine\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.driver.bindAddress\",\"127.0.0.1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 19:58:31 WARN SparkContext: The path ReviewClass.py has been added already. Overwriting of added paths is not supported in the current version.\n"
     ]
    }
   ],
   "source": [
    "from ReviewClass import Review\n",
    "\n",
    "spark.sparkContext.addPyFile('ReviewClass.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from csv files into dataframe\n",
    "df1 = pd.read_csv('reviews/train-1.csv')\n",
    "df2 = pd.read_csv('reviews/train-2.csv')\n",
    "df3 = pd.read_csv('reviews/train-3.csv')\n",
    "df4 = pd.read_csv('reviews/train-4.csv')\n",
    "df5 = pd.read_csv('reviews/train-5.csv')\n",
    "df6 = pd.read_csv('reviews/train-6.csv')\n",
    "df7 = pd.read_csv('reviews/train-7.csv')\n",
    "df8 = pd.read_csv('reviews/train-8.csv')\n",
    "\n",
    "df_train = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8])\n",
    "\n",
    "# Change name of first column\n",
    "df_train.rename(columns={ df_train.columns[0]: \"review_id\" }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data from dataframe into spark session\n",
    "reviews = [Review(**kwargs) for kwargs in df_train.to_dict(orient='records')]\n",
    "\n",
    "review_rdd = spark.sparkContext.parallelize(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 586944), (1, 223100), (2, 58451), (3, 2086906), (4, 148683), (5, 69346), (6, 1550010), (7, 3770), (8, 5496), (9, 68815), (10, 37976), (11, 104513), (12, 53078), (13, 35703), (14, 19181), (15, 22642), (16, 67598), (17, 23619), (18, 38034), (19, 11432), (20, 13222), (21, 4724), (22, 13235), (23, 2963), (24, 26362), (25, 3123), (26, 4945), (27, 83), (28, 1259)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 19:59:29 WARN TaskSetManager: Stage 12 contains a task of very large size (6671 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "# PoC of total character count\n",
    "total_character_count_per_product_category_id = review_rdd\\\n",
    "    .flatMap(lambda review: [(review.product_category_id, review.ReviewBodyCharCount())])\\\n",
    "    .reduceByKey(lambda count1, count2: count1 + count2)\\\n",
    "    .sortByKey()\\\n",
    "    .collect()\n",
    "\n",
    "print(total_character_count_per_product_category_id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96f9418e69eaeb26f09100da13ed59566d98b4e8252c70eed69f1604a08955be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
